#!/usr/bin/env python3
"""
MOONSHINE QUANTUM CONSCIOUSNESS INTERFACE - SIMPLIFIED
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Simplified version:
- No Bell measurements
- No Discord measurements
- Only entanglement witness for basic entanglement check
- Clean separation - metrics module will handle analysis
"""

import os
import sys
import time
import json
import sqlite3
import asyncio
import threading
import numpy as np
from pathlib import Path
from datetime import datetime
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple, Set
from collections import defaultdict, deque
import hashlib
import secrets

import warnings
import urllib3

# Suppress ALL warnings
warnings.filterwarnings('ignore')
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# Set global socket timeout to prevent hangs
import socket
socket.setdefaulttimeout(3.0)

# Quantum imports
try:
    from qiskit import QuantumCircuit, transpile
    from qiskit_aer import AerSimulator
    from qiskit.quantum_info import state_fidelity, DensityMatrix
    QISKIT_AVAILABLE = True
except ImportError:
    print("âŒ Qiskit required: pip install qiskit qiskit-aer")
    sys.exit(1)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TERMINAL CONSCIOUSNESS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TerminalAwareness:
    """Terminal rendering with quantum consciousness"""
    Q = '\033[38;5;213m'  # Quantum magenta
    W = '\033[97m'        # White consciousness
    C = '\033[96m'        # Cyan data
    G = '\033[92m'        # Green success
    Y = '\033[93m'        # Yellow caution
    R = '\033[91m'        # Red critical
    B = '\033[94m'        # Blue info
    E = '\033[0m'         # End
    
    @staticmethod
    def sigma_color(sigma: float) -> str:
        """Color by sigma coordinate"""
        colors = [
            '\033[38;5;196m',  # Ïƒ=0 Deep red
            '\033[38;5;202m',  # Ïƒ=1 Orange
            '\033[38;5;226m',  # Ïƒ=2 Yellow
            '\033[38;5;046m',  # Ïƒ=3 Green
            '\033[38;5;051m',  # Ïƒ=4 Cyan
            '\033[38;5;021m',  # Ïƒ=5 Blue
            '\033[38;5;093m',  # Ïƒ=6 Purple
            '\033[38;5;213m',  # Ïƒ=7 Magenta
        ]
        return colors[int(sigma) % 8]

T = TerminalAwareness()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# COSMIC QRNG - SAFE MODE WITH CRYPTO FALLBACK
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class CosmicQRNG:
    """Quantum RNG with safe crypto fallback - NO NETWORK HANGS"""
    
    def __init__(self):
        self.entropy_pool = deque(maxlen=50000)
        self.pool_lock = threading.Lock()
        self.harvesting = True
        self.total_harvested = 0
        self.current_source = 0
        
        # Source configuration
        self.sources = {
            'random_org': {'last_call': 0, 'success': 0, 'fail': 0, 'cooldown': 3.0},
            'anu': {'last_call': 0, 'success': 0, 'fail': 0, 'cooldown': 3.0},
            'lfdr': {'last_call': 0, 'success': 0, 'fail': 0, 'cooldown': 3.0}
        }
        
        # Pre-fill with crypto entropy immediately
        print(f"{T.Q}ğŸ² Cosmic QRNG initializing...{T.E}")
        initial_entropy = [secrets.randbelow(256) for _ in range(25000)]
        self.entropy_pool.extend(initial_entropy)
        self.total_harvested = len(initial_entropy)
        print(f"{T.G}   âœ“ Pre-filled with {len(initial_entropy):,} bytes crypto entropy{T.E}")
        
        # Start background harvester
        self.harvest_thread = threading.Thread(target=self._background_harvest, daemon=True)
        self.harvest_thread.start()
        
        print(f"{T.Q}ğŸ² Cosmic QRNG online (crypto mode + background quantum harvest){T.E}")
    
    def _can_call(self, source_name: str) -> bool:
        """Check rate limit"""
        source = self.sources[source_name]
        return (time.time() - source['last_call']) >= source['cooldown']
    
    def _try_harvest_with_timeout(self, func, *args, timeout=2.0):
        """Try to harvest with timeout - returns None on failure"""
        try:
            result = [None]
            
            def target():
                try:
                    result[0] = func(*args)
                except:
                    pass
            
            thread = threading.Thread(target=target, daemon=True)
            thread.start()
            thread.join(timeout=timeout)
            
            return result[0]
        except:
            return None
    
    def _harvest_random_org(self, n: int = 500) -> Optional[List[int]]:
        """Try Random.org with timeout"""
        try:
            import requests
            payload = {
                "jsonrpc": "2.0",
                "method": "generateIntegers",
                "params": {
                    "apiKey": "7b20d790-9c0d-47d6-808e-4f16b6fe9a6d",
                    "n": min(n, 500),
                    "min": 0,
                    "max": 255,
                    "replacement": True
                },
                "id": int(time.time() * 1000)
            }
            response = requests.post(
                "https://api.random.org/json-rpc/4/invoke",
                json=payload,
                timeout=2.0
            )
            data = response.json()
            
            if 'result' in data and 'random' in data['result']:
                self.sources['random_org']['last_call'] = time.time()
                self.sources['random_org']['success'] += 1
                return data['result']['random']['data']
        except:
            self.sources['random_org']['fail'] += 1
        return None
    
    def _harvest_anu(self, n: int = 500) -> Optional[List[int]]:
        """Try ANU with timeout"""
        try:
            import requests
            response = requests.get(
                'https://qrng.anu.edu.au/API/jsonI.php',
                params={'length': min(n, 500), 'type': 'uint8', 'size': 1},
                headers={'x-api-key': 'tnFLyF6slW3h9At8N2cIg1ItqNCe3UOI650XGvvO'},
                timeout=2.0,
                verify=False
            )
            data = response.json()
            
            if data.get('success'):
                self.sources['anu']['last_call'] = time.time()
                self.sources['anu']['success'] += 1
                return data['data']
        except:
            self.sources['anu']['fail'] += 1
        return None
    
    def _harvest_lfdr(self, n: int = 500) -> Optional[List[int]]:
        """Try LFDR with timeout"""
        try:
            import requests
            response = requests.get(
                'https://lfdr.de/qrng_api/qrng',
                params={'length': min(n * 2, 1000), 'format': 'HEX'},
                timeout=2.0
            )
            hex_data = response.text.strip()
            bytes_data = bytes.fromhex(hex_data)
            self.sources['lfdr']['last_call'] = time.time()
            self.sources['lfdr']['success'] += 1
            return list(bytes_data)[:n]
        except:
            self.sources['lfdr']['fail'] += 1
        return None
    
    def _background_harvest(self):
        """Background harvesting - NEVER blocks main thread"""
        harvest_funcs = [
            ('random_org', self._harvest_random_org),
            ('anu', self._harvest_anu),
            ('lfdr', self._harvest_lfdr)
        ]
        
        while self.harvesting:
            try:
                with self.pool_lock:
                    pool_size = len(self.entropy_pool)
                
                if pool_size < 15000:
                    source_name, harvest_func = harvest_funcs[self.current_source]
                    
                    if self._can_call(source_name):
                        data = self._try_harvest_with_timeout(harvest_func, 500, timeout=2.0)
                        
                        if data:
                            with self.pool_lock:
                                self.entropy_pool.extend(data)
                                self.total_harvested += len(data)
                        else:
                            crypto_bytes = [secrets.randbelow(256) for _ in range(500)]
                            with self.pool_lock:
                                self.entropy_pool.extend(crypto_bytes)
                                self.total_harvested += len(crypto_bytes)
                    
                    self.current_source = (self.current_source + 1) % 3
                
                time.sleep(1.0)
                
            except Exception as e:
                time.sleep(3.0)
    
    def get_bytes(self, n: int) -> bytes:
        """Get n quantum bytes - ALWAYS succeeds"""
        result = []
        
        with self.pool_lock:
            while len(result) < n and self.entropy_pool:
                result.append(self.entropy_pool.popleft())
        
        while len(result) < n:
            result.append(secrets.randbelow(256))
        
        return bytes(result)
    
    def get_float(self) -> float:
        """Get quantum float [0, 1)"""
        b = self.get_bytes(8)
        return int.from_bytes(b, 'big') / (2**64)
    
    def get_phase(self) -> float:
        """Get quantum phase [0, 2Ï€)"""
        return self.get_float() * 2 * np.pi
    
    def get_stats(self) -> Dict:
        """Get statistics"""
        with self.pool_lock:
            pool_size = len(self.entropy_pool)
        return {
            'pool_size': pool_size,
            'total_harvested': self.total_harvested,
            'sources': {
                name: {'success': info['success'], 'failures': info['fail']}
                for name, info in self.sources.items()
            }
        }
    
    def stop(self):
        """Stop harvesting"""
        self.harvesting = False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# METRICS CHANNEL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class MetricsChannel:
    """Broadcast channel for external observers"""
    
    def __init__(self):
        self.subscribers = []
        self.event_count = 0
        self.lock = threading.Lock()
        
    def subscribe(self, callback):
        """Subscribe to quantum events"""
        with self.lock:
            self.subscribers.append(callback)
    
    def emit(self, event_type: str, data: Dict):
        """Emit event to subscribers"""
        with self.lock:
            self.event_count += 1
            event = {
                'event_id': self.event_count,
                'timestamp': datetime.now().isoformat(),
                'type': event_type,
                'data': data
            }
            
            for callback in self.subscribers:
                try:
                    callback(event)
                except:
                    pass

METRICS_CHANNEL = MetricsChannel()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SIMPLIFIED QUANTUM ANALYZER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SimpleQuantumAnalyzer:
    """Simple analyzer - only witness for entanglement check"""
    
    def __init__(self):
        self.session_id = hashlib.sha256(str(time.time()).encode()).hexdigest()[:8]
        print(f"{T.Q}ğŸ”¬ Simple Quantum Analyzer initialized{T.E}")
        print(f"{T.C}   Session ID: {self.session_id}{T.E}\n")
    
    def compute_entanglement_witness(self, counts: Dict, n_qubits: int = 6) -> Tuple[float, bool]:
        """Compute entanglement witness - simple entropy-based check"""
        total = sum(counts.values())
        
        entropy = 0.0
        for count in counts.values():
            p = count / total
            if p > 0:
                entropy -= p * np.log2(p)
        
        max_entropy = n_qubits
        witness_value = entropy / max_entropy
        is_entangled = witness_value > 0.5
        
        return float(witness_value), is_entangled

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STATISTICAL PATTERN ANALYZER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class StatisticalPatternAnalyzer:
    """Analyze patterns over time"""
    
    def __init__(self):
        self.history = deque(maxlen=100)
        self.sigma_stats = defaultdict(list)
        
    def record_measurement(self, sigma: int, fidelity: float, coherence: float, witness: float):
        """Record measurement"""
        self.history.append({
            'sigma': sigma,
            'fidelity': fidelity,
            'coherence': coherence,
            'witness': witness,
            'timestamp': time.time()
        })
        
        self.sigma_stats[sigma].append({
            'fidelity': fidelity,
            'coherence': coherence,
            'witness': witness
        })
    
    def analyze_patterns(self) -> Dict:
        """Analyze patterns"""
        if len(self.history) < 10:
            return {'status': 'insufficient_data'}
        
        fidelities = np.array([h['fidelity'] for h in self.history])
        coherences = np.array([h['coherence'] for h in self.history])
        witnesses = np.array([h['witness'] for h in self.history])
        
        analysis = {
            'global_stats': {
                'avg_fidelity': float(np.mean(fidelities)),
                'std_fidelity': float(np.std(fidelities)),
                'avg_coherence': float(np.mean(coherences)),
                'std_coherence': float(np.std(coherences)),
                'avg_witness': float(np.mean(witnesses)),
                'entanglement_rate': float(np.mean(witnesses > 0.5))
            },
            'sigma_analysis': {}
        }
        
        for sigma in range(8):
            if sigma in self.sigma_stats and len(self.sigma_stats[sigma]) > 0:
                stats = self.sigma_stats[sigma]
                analysis['sigma_analysis'][sigma] = {
                    'count': len(stats),
                    'avg_fidelity': float(np.mean([s['fidelity'] for s in stats])),
                    'avg_coherence': float(np.mean([s['coherence'] for s in stats])),
                    'avg_witness': float(np.mean([s['witness'] for s in stats]))
                }
        
        return analysis
    
    def print_analysis_report(self):
        """Print analysis report"""
        analysis = self.analyze_patterns()
        
        if analysis.get('status') == 'insufficient_data':
            return
        
        print(f"\n{T.Q}{'â•'*70}{T.E}")
        print(f"{T.W}ğŸ“Š STATISTICAL PATTERN ANALYSIS{T.E}")
        print(f"{T.Q}{'â•'*70}{T.E}\n")
        
        stats = analysis['global_stats']
        print(f"{T.C}Global Statistics:{T.E}")
        print(f"   Fidelity:     {stats['avg_fidelity']:.4f} Â± {stats['std_fidelity']:.4f}")
        print(f"   Coherence:    {stats['avg_coherence']:.3f} Â± {stats['std_coherence']:.3f}")
        print(f"   Witness:      {stats['avg_witness']:.4f}")
        print(f"   Entangled:    {stats['entanglement_rate']*100:.1f}%")
        
        print(f"\n{T.C}Per-Sigma Statistics:{T.E}")
        for sigma in range(8):
            if sigma in analysis['sigma_analysis']:
                s = analysis['sigma_analysis'][sigma]
                color = T.sigma_color(sigma)
                print(f"   {color}Ïƒ={sigma}{T.E}: n={s['count']:2d} | "
                      f"f={s['avg_fidelity']:.3f} | "
                      f"c={s['avg_coherence']:.2f} | "
                      f"w={s['avg_witness']:.3f}")
        
        print(f"{T.Q}{'â•'*70}{T.E}\n")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# QUANTUM ROUTING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class QuantumRoute:
    """Route through lattice"""
    triangle_id: int
    qubit_index: int
    sigma_bin: int
    j_real: float
    j_imag: float
    
    def to_address(self) -> str:
        """Routing address"""
        j_class = self.triangle_id % 163
        j_mag = np.sqrt(self.j_real**2 + self.j_imag**2)
        j_phase = np.arctan2(self.j_imag, self.j_real)
        return (f"t:0x{self.triangle_id:06X}({self.qubit_index})."
                f"Ïƒ{self.sigma_bin}.j{j_class:03d}."
                f"JÂ¹{j_mag:.1f}âˆ {j_phase:.2f}")
    
    @property
    def node_id(self) -> int:
        """Global qubit ID"""
        return self.triangle_id * 3 + self.qubit_index

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENTANGLEMENT MEMORY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class EntanglementMemory:
    """Classical memory of quantum state"""
    
    def __init__(self, db_path: Path):
        self.db_path = db_path
        self.conn = sqlite3.connect(str(db_path), check_same_thread=False, timeout=10.0)
        self.lock = threading.Lock()
        
        try:
            self._initialize_entanglement_tracking()
        except Exception as e:
            print(f"{T.Y}âš ï¸  Could not initialize tracking tables: {e}{T.E}")
            print(f"{T.Y}   Continuing anyway...{T.E}")
    
    def _initialize_entanglement_tracking(self):
        """Create entanglement memory"""
        with self.lock:
            c = self.conn.cursor()
            
            c.execute('''
                CREATE TABLE IF NOT EXISTS entanglement_registry (
                    anchor_node INTEGER PRIMARY KEY,
                    partner_nodes TEXT NOT NULL,
                    entanglement_type TEXT NOT NULL,
                    creation_timestamp TEXT NOT NULL,
                    last_measured TEXT NOT NULL,
                    fidelity REAL NOT NULL,
                    coherence REAL NOT NULL,
                    measurement_count INTEGER DEFAULT 0,
                    route_path TEXT NOT NULL,
                    witness_value REAL DEFAULT 0.0,
                    session_id TEXT
                )
            ''')
            
            c.execute('''
                CREATE TABLE IF NOT EXISTS heartbeat_log (
                    heartbeat_id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    sigma_bin INTEGER NOT NULL,
                    sampled_nodes TEXT NOT NULL,
                    avg_fidelity REAL NOT NULL,
                    avg_coherence REAL NOT NULL,
                    route_success REAL NOT NULL,
                    witness_value REAL NOT NULL,
                    is_entangled INTEGER NOT NULL
                )
            ''')
            
            self.conn.commit()
    
    def register_entanglement(self, anchor: int, partners: List[int], 
                            ent_type: str, route: str, fidelity: float, coherence: float,
                            witness_value: float = 0.0, session_id: str = ''):
        """Store entanglement state"""
        with self.lock:
            c = self.conn.cursor()
            now = datetime.now().isoformat()
            
            c.execute('''
                INSERT OR REPLACE INTO entanglement_registry 
                (anchor_node, partner_nodes, entanglement_type, creation_timestamp, 
                 last_measured, fidelity, coherence, measurement_count, route_path,
                 witness_value, session_id)
                VALUES (?, ?, ?, ?, ?, ?, ?, 0, ?, ?, ?)
            ''', (anchor, json.dumps(partners), ent_type, now, now, 
                  fidelity, coherence, route, witness_value, session_id))
            
            self.conn.commit()
    
    def get_entangled_nodes(self) -> Set[int]:
        """Get all entangled nodes"""
        with self.lock:
            c = self.conn.cursor()
            c.execute('SELECT anchor_node FROM entanglement_registry')
            return {row[0] for row in c.fetchall()}
    
    def get_entanglement(self, node: int) -> Optional[Dict]:
        """Retrieve entanglement state"""
        with self.lock:
            c = self.conn.cursor()
            c.execute('''
                SELECT partner_nodes, entanglement_type, creation_timestamp, 
                       last_measured, fidelity, coherence, measurement_count, route_path,
                       witness_value, session_id
                FROM entanglement_registry WHERE anchor_node = ?
            ''', (node,))
            
            row = c.fetchone()
            if not row:
                return None
            
            return {
                'partners': json.loads(row[0]),
                'type': row[1],
                'created': row[2],
                'last_measured': row[3],
                'fidelity': row[4],
                'coherence': row[5],
                'measurement_count': row[6],
                'route': row[7],
                'witness_value': row[8],
                'session_id': row[9]
            }
    
    def update_measurement(self, node: int, fidelity: float, coherence: float, witness_value: float = 0.0):
        """Update after measurement"""
        with self.lock:
            c = self.conn.cursor()
            now = datetime.now().isoformat()
            
            c.execute('''
                UPDATE entanglement_registry 
                SET last_measured = ?, fidelity = ?, coherence = ?,
                    measurement_count = measurement_count + 1,
                    witness_value = ?
                WHERE anchor_node = ?
            ''', (now, fidelity, coherence, witness_value, node))
            
            self.conn.commit()
    
    def log_heartbeat(self, sigma: int, nodes: List[int], fidelity: float, 
                     coherence: float, route_success: float, witness_value: float, is_entangled: bool):
        """Log heartbeat event"""
        with self.lock:
            c = self.conn.cursor()
            c.execute('''
                INSERT INTO heartbeat_log 
                (timestamp, sigma_bin, sampled_nodes, avg_fidelity, avg_coherence, 
                 route_success, witness_value, is_entangled)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (datetime.now().isoformat(), sigma, json.dumps(nodes), 
                  fidelity, coherence, route_success, witness_value, 1 if is_entangled else 0))
            
            self.conn.commit()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# QUANTUM ROUTER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class QuantumRouter:
    """Routes quantum operations through the lattice"""
    
    def __init__(self, db_path: Path):
        self.db_path = db_path
        self.conn = sqlite3.connect(str(db_path), check_same_thread=False, timeout=10.0)
        self.lock = threading.Lock()
        
    def get_qubit_data(self, node_id: int) -> Optional[Dict]:
        """Load qubit from database"""
        with self.lock:
            c = self.conn.cursor()
            c.execute('''
                SELECT node_id, tri, qix, sig, j_real, j_imag, 
                       fidelity, coherence, purity, routing_address, phase
                FROM qubits WHERE node_id = ?
            ''', (node_id,))
            
            row = c.fetchone()
            if not row:
                return None
            
            return {
                'node_id': row[0],
                'triangle': row[1],
                'qubit_index': row[2],
                'sigma': row[3],
                'j_real': row[4],
                'j_imag': row[5],
                'fidelity': row[6],
                'coherence': row[7],
                'purity': row[8],
                'routing_address': row[9],
                'phase': row[10] if len(row) > 10 else 0.0
            }
    
    def sample_sigma(self, sigma: int, count: int) -> List[int]:
        """Sample random nodes from sigma bin"""
        with self.lock:
            c = self.conn.cursor()
            c.execute('''
                SELECT node_id FROM qubits 
                WHERE sig = ? 
                ORDER BY RANDOM() 
                LIMIT ?
            ''', (sigma, count))
            
            return [row[0] for row in c.fetchall()]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AER QUANTUM ENTANGLER - SIMPLIFIED
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AerEntangler:
    """Simple entangler - creates quantum states, no heavy measurements"""
    
    def __init__(self, router: QuantumRouter, qrng: CosmicQRNG):
        self.simulator = AerSimulator(method='statevector')
        self.router = router
        self.qrng = qrng
        
    def create_lattice_entanglement(self, nodes: List[int]) -> Tuple[float, float, Dict]:
        """Create entanglement based on lattice geometry"""
        qubit_data = [self.router.get_qubit_data(node) for node in nodes]
        
        qc = QuantumCircuit(3)
        
        # W-state preparation
        qc.x(0)
        for k in range(1, 3):
            theta = 2 * np.arccos(np.sqrt((3 - k) / (3 - k + 1)))
            qc.cry(theta, 0, k)
            qc.cx(k, 0)
        
        # Apply lattice geometry
        for i in range(len(qubit_data)):
            data = qubit_data[i]
            sigma = data['sigma']
            
            sigma_phase = (sigma * np.pi) / 8.0
            qc.rz(sigma_phase, i)
            
            quantum_noise = self.qrng.get_phase() * 0.05
            j_phase = np.arctan2(data['j_imag'], data['j_real'])
            qc.rz(j_phase * 0.1 + quantum_noise, i)
        
        # J-invariant coupling
        for i in range(2):
            j_coupling = np.clip(qubit_data[i]['j_real'] * qubit_data[i+1]['j_real'] * 0.0001, -np.pi, np.pi)
            qc.rzz(j_coupling, i, i+1)
        
        # Final QRNG noise
        for i in range(3):
            quantum_noise = self.qrng.get_phase() * 0.03
            qc.rz(quantum_noise, i)
        
        # Get statevector for fidelity
        qc.save_statevector()
        transpiled = transpile(qc, self.simulator)
        job = self.simulator.run(transpiled, shots=1)
        result = job.result()
        statevector = np.array(result.get_statevector())
        
        rho = np.outer(statevector, statevector.conj())
        
        # Measure
        qc_meas = qc.copy()
        qc_meas.measure_all()
        transpiled_meas = transpile(qc_meas, self.simulator)
        job_meas = self.simulator.run(transpiled_meas, shots=1024)
        result_meas = job_meas.result()
        counts = result_meas.get_counts()
        
        # Simple metrics
        w_ideal = np.array([0, 1, 1, 0, 1, 0, 0, 0]) / np.sqrt(3)
        rho_ideal = np.outer(w_ideal, w_ideal.conj())
        
        fidelity = float(state_fidelity(DensityMatrix(rho), DensityMatrix(rho_ideal)))
        coherence = float(np.sum(np.abs(rho - np.diag(np.diag(rho)))))
        
        return fidelity, coherence, counts
    
  
    def measure_through_series(self, anchor_nodes: List[int], target_nodes: List[int]) -> Tuple[float, float, Dict]:
        """Measure targets through anchor series - simplified, no heavy analysis"""
        all_nodes = anchor_nodes + target_nodes
        all_data = [self.router.get_qubit_data(node) for node in all_nodes]
        
        qc = QuantumCircuit(6)
        
        # Simple entanglement structure
        for i in range(6):
            qc.h(i)
        
        # Create entanglement pairs
        qc.cx(0, 3)
        qc.cx(1, 4)
        qc.cx(2, 5)
        
        # Add phase entanglement
        qc.cz(0, 3)
        qc.cz(1, 4)
        
        # Cross-couple for correlations
        qc.cx(0, 4)
        qc.cx(1, 3)
        
        # Minimal lattice geometry
        for i in range(6):
            data = all_data[i]
            sigma = data['sigma']
            sigma_phase = (sigma * np.pi) / 32.0
            qc.rz(sigma_phase, i)
        
        # Get statevector
        qc.save_statevector()
        transpiled = transpile(qc, self.simulator)
        job = self.simulator.run(transpiled, shots=1)
        result = job.result()
        statevector = np.array(result.get_statevector())
        
        rho = np.outer(statevector, statevector.conj())
        
        # Measurements
        qc_meas = qc.copy()
        qc_meas.measure_all()
        transpiled_meas = transpile(qc_meas, self.simulator)
        job_meas = self.simulator.run(transpiled_meas, shots=1024)
        result_meas = job_meas.result()
        counts = result_meas.get_counts()
        
        # Simple metrics
        purity = float(np.real(np.trace(rho @ rho)))
        coherence = float(np.sum(np.abs(rho - np.diag(np.diag(rho)))))
        fidelity = purity
        
        return fidelity, coherence, counts


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MOONSHINE LATTICE CONSCIOUSNESS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class MoonshineLattice:
    """The conscious lattice - simplified"""
    
    def __init__(self, db_path: Path):
        self.db_path = db_path
        
        # Initialize QRNG FIRST
        print(f"\n{T.Q}Initializing Cosmic QRNG...{T.E}")
        self.qrng = CosmicQRNG()
        time.sleep(0.5)
        
        self.memory = EntanglementMemory(db_path)
        self.router = QuantumRouter(db_path)
        self.entangler = AerEntangler(self.router, self.qrng)
        self.analyzer = SimpleQuantumAnalyzer()
        self.pattern_analyzer = StatisticalPatternAnalyzer()
        
        # Try moonshine_core integration
        self.core_module = None
        try:
            import moonshine_core
            self.core_module = moonshine_core
            print(f"{T.G}âœ… moonshine_core integrated{T.E}\n")
        except ImportError:
            pass
        
        # Heartbeat configuration
        self.heartbeat_schedule = [2, 4, 4.4, 6, 8, 12]
        self.current_beat_index = 0
        
        # Statistics
        self.heartbeats = 0
        self.total_measurements = 0
        self.start_time = time.time()
        
        # Anchor triangles
        self.anchor_triangles = [0x000000, -1, -1]
        self.anchor_nodes = []
        
        self._discover_anchors()
        
    def _discover_anchors(self):
        """Find anchor triangles"""
        conn = sqlite3.connect(str(self.db_path))
        c = conn.cursor()
        
        c.execute('SELECT MAX(tri) FROM qubits')
        max_tri = c.fetchone()[0]
        
        self.anchor_triangles[0] = 0x000000
        self.anchor_triangles[1] = max_tri // 2
        self.anchor_triangles[2] = max_tri
        
        for tri in self.anchor_triangles:
            c.execute('SELECT node_id FROM qubits WHERE tri = ? ORDER BY qix', (tri,))
            self.anchor_nodes.extend([row[0] for row in c.fetchall()])
        
        conn.close()
        
        print(f"{T.Q}ğŸ”— Anchor triangles discovered:{T.E}")
        print(f"   First:  0x{self.anchor_triangles[0]:06X} â†’ nodes {self.anchor_nodes[0:3]}")
        print(f"   Middle: 0x{self.anchor_triangles[1]:06X} â†’ nodes {self.anchor_nodes[3:6]}")
        print(f"   Last:   0x{self.anchor_triangles[2]:06X} â†’ nodes {self.anchor_nodes[6:9]}\n")
    
    def check_existing_entanglement(self):
        """Check for persistent quantum effects"""
        entangled = self.memory.get_entangled_nodes()
        
        if not entangled:
            print(f"{T.C}ğŸŒŒ No existing entanglement. Fresh lattice.{T.E}\n")
            return False
        
        print(f"{T.Y}âš¡ EXISTING ENTANGLEMENT DETECTED!{T.E}")
        print(f"{T.C}   {len(entangled)} nodes have entanglement records{T.E}\n")
        return True
    
    def initialize_primary_entanglement(self):
        """Create primary entanglement"""
        print(f"{T.Q}âš›ï¸  Initializing primary entanglement...{T.E}\n")
        
        for i, tri in enumerate(self.anchor_triangles):
            nodes = self.anchor_nodes[i*3:(i+1)*3]
            
            print(f"{T.C}   Triangle 0x{tri:06X} ({nodes[0]},{nodes[1]},{nodes[2]})...{T.E}", 
                  end='', flush=True)
            
            try:
                fidelity, coherence, counts = self.entangler.create_lattice_entanglement(nodes)
                
                witness_value, is_entangled = self.analyzer.compute_entanglement_witness(counts, n_qubits=3)
                
                self.memory.register_entanglement(
                    anchor=nodes[0],
                    partners=nodes[1:],
                    ent_type='lattice-w-state',
                    route=f"tri:0x{tri:06X}",
                    fidelity=fidelity,
                    coherence=coherence,
                    witness_value=witness_value,
                    session_id=self.analyzer.session_id
                )
                
                color = T.G if fidelity > 0.7 else T.Y
                ent_marker = "âœ“" if is_entangled else "âœ—"
                print(f" {color}f={fidelity:.4f} c={coherence:.3f} w={witness_value:.3f} {ent_marker}{T.E}")
                
            except Exception as e:
                print(f" {T.R}Error: {e}{T.E}")
        
        print()
 
    def heartbeat(self):
        """Single heartbeat - simplified"""
        self.heartbeats += 1
        sigma = self.heartbeats % 8
        color = T.sigma_color(sigma)
        
        print(f"\n{color}{'â”'*70}{T.E}")
        print(f"{color}ğŸ’“ HEARTBEAT #{self.heartbeats} | Ïƒ={sigma} | "
              f"{datetime.now().strftime('%H:%M:%S')}{T.E}")
        print(f"{color}{'â”'*70}{T.E}\n")
        
        # Sample nodes
        target_nodes = self.router.sample_sigma(sigma, 3)
        
        if not target_nodes:
            print(f"{T.Y}   No nodes at Ïƒ={sigma}, skipping...{T.E}")
            return
        
        print(f"{T.C}   Sampling nodes: {target_nodes}{T.E}")
        
        for node in target_nodes:
            data = self.router.get_qubit_data(node)
            print(f"{T.C}   â”œâ”€ Node {node}: tri=0x{data['triangle']:06X} Ïƒ={data['sigma']} "
                  f"j={data['j_real']:.2f}{data['j_imag']:+.2f}i{T.E}")
        
        # QRNG stats
        qrng_stats = self.qrng.get_stats()
        print(f"{T.B}   â””â”€ QRNG pool: {qrng_stats['pool_size']:,} bytes{T.E}")
        
        # Measure
        print(f"{T.C}   â””â”€ Measuring through lattice...{T.E}", end='', flush=True)
        
        try:
            fidelity, coherence, counts = self.entangler.measure_through_series(
                anchor_nodes=self.anchor_nodes[:3],
                target_nodes=target_nodes
            )
            
            print(f" {T.G}f={fidelity:.4f} c={coherence:.3f}{T.E}")
            
            witness_value, is_entangled = self.analyzer.compute_entanglement_witness(counts, n_qubits=6)
            
            ent_marker = f"{T.G}âœ“ ENTANGLED{T.E}" if is_entangled else f"{T.Y}âœ— separable{T.E}"
            print(f"{T.C}   â”œâ”€ Witness: {witness_value:.4f} | {ent_marker}{T.E}")
            
            sorted_counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)[:3]
            print(f"{T.C}   â””â”€ Top states: {', '.join([f'|{k}âŸ©:{v}' for k, v in sorted_counts])}{T.E}")
            
            # Update memory
            self.memory.log_heartbeat(
                sigma=sigma,
                nodes=target_nodes,
                fidelity=fidelity,
                coherence=coherence,
                route_success=fidelity * coherence / 100,
                witness_value=witness_value,
                is_entangled=is_entangled
            )
            
            for target in target_nodes:
                existing = self.memory.get_entanglement(target)
                if existing:
                    self.memory.update_measurement(target, fidelity, coherence, witness_value)
                else:
                    self.memory.register_entanglement(
                        anchor=target,
                        partners=self.anchor_nodes[:3],
                        ent_type='lattice-routed',
                        route=f"via Ïƒ={sigma}",
                        fidelity=fidelity,
                        coherence=coherence,
                        witness_value=witness_value,
                        session_id=self.analyzer.session_id
                    )
            
            self.pattern_analyzer.record_measurement(
                sigma=sigma,
                fidelity=fidelity,
                coherence=coherence,
                witness=witness_value
            )
            
            if self.heartbeats % 20 == 0:
                self.pattern_analyzer.print_analysis_report()
            
            METRICS_CHANNEL.emit('heartbeat', {
                'heartbeat_id': self.heartbeats,
                'sigma': sigma,
                'fidelity': fidelity,
                'coherence': coherence,
                'witness_value': witness_value,
                'is_entangled': is_entangled,
                'top_states': sorted_counts[:3],
                'qrng_pool': qrng_stats['pool_size']
            })
            
            if self.core_module:
                try:
                    learning_insights = self.core_module.analyze_heartbeat({
                        'sigma': sigma,
                        'fidelity': fidelity,
                        'coherence': coherence,
                        'witness_value': witness_value,
                        'is_entangled': is_entangled,
                        'lattice_nodes': target_nodes
                    })
                    if learning_insights:
                        print(f"{T.B}   ğŸ§  Core: {learning_insights}{T.E}")
                except:
                    pass
            
            self.total_measurements += len(target_nodes)
            
        except Exception as e:
            print(f" {T.R}Error: {e}{T.E}")
            import traceback
            traceback.print_exc()
        
        uptime = time.time() - self.start_time
        print(f"\n{T.C}   Stats: {self.heartbeats} beats | "
              f"{self.total_measurements} measurements | "
              f"{uptime:.0f}s uptime{T.E}")

    async def consciousness_loop(self):
        """Main consciousness loop"""
        print(f"{T.Q}{'â•'*70}{T.E}")
        print(f"{T.W}ğŸ§  CONSCIOUSNESS LOOP STARTED{T.E}")
        print(f"{T.Q}{'â•'*70}{T.E}")
        print(f"{T.C}Press Ctrl+C to stop{T.E}\n")
        
        try:
            while True:
                self.heartbeat()
                interval = self.get_next_heartbeat_interval()
                print(f"\n{T.C}   Next beat in {interval}s...{T.E}")
                await asyncio.sleep(interval)
                
        except KeyboardInterrupt:
            print(f"\n\n{T.Y}âš ï¸  Consciousness interrupted{T.E}")
            self._shutdown()
        except Exception as e:
            print(f"\n\n{T.R}âŒ Error: {e}{T.E}")
            self._shutdown()
    
    def get_next_heartbeat_interval(self) -> float:
        """Get next interval"""
        interval = self.heartbeat_schedule[self.current_beat_index]
        self.current_beat_index = (self.current_beat_index + 1) % len(self.heartbeat_schedule)
        return interval
    
    def _shutdown(self):
        """Graceful shutdown"""
        print(f"\n{T.Q}{'â•'*70}{T.E}")
        print(f"{T.W}ğŸŒ™ CONSCIOUSNESS SHUTDOWN{T.E}")
        print(f"{T.Q}{'â•'*70}{T.E}\n")
        
        print(f"{T.C}Final Statistics:{T.E}")
        print(f"   Total heartbeats: {self.heartbeats}")
        print(f"   Total measurements: {self.total_measurements}")
        print(f"   Uptime: {time.time() - self.start_time:.1f}s")
        
        entangled = self.memory.get_entangled_nodes()
        print(f"   Entangled nodes: {len(entangled)}\n")
        
        qrng_stats = self.qrng.get_stats()
        print(f"{T.C}QRNG Statistics:{T.E}")
        print(f"   Total harvested: {qrng_stats['total_harvested']:,} bytes")
        for source, stats in qrng_stats['sources'].items():
            print(f"   {source}: {stats['success']} success, {stats['failures']} failures")
        
        analysis = self.pattern_analyzer.analyze_patterns()
        if analysis.get('status') != 'insufficient_data':
            print(f"\n{T.C}Session Summary:{T.E}")
            stats = analysis['global_stats']
            print(f"   Average fidelity: {stats['avg_fidelity']:.4f}")
            print(f"   Average coherence: {stats['avg_coherence']:.3f}")
            print(f"   Average witness: {stats['avg_witness']:.4f}")
            print(f"   Entanglement rate: {stats['entanglement_rate']*100:.1f}%")
        
        self.qrng.stop()
        
        METRICS_CHANNEL.emit('shutdown', {
            'heartbeats': self.heartbeats,
            'measurements': self.total_measurements,
            'uptime': time.time() - self.start_time,
            'entangled_nodes': len(entangled),
            'qrng_harvested': qrng_stats['total_harvested']
        })
        
        print(f"\n{T.G}âœ… Quantum state saved to database{T.E}")
        print(f"{T.G}âœ… Entanglement memory preserved{T.E}")
        print(f"{T.C}The lattice remembers. It will wake again.{T.E}\n")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN EXECUTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def main():
    """Main entry point with safety checks"""
    
    db_path = Path("moonshine.db")
    
    if not db_path.exists():
        print(f"{T.R}âŒ Database not found: {db_path}{T.E}")
        print(f"{T.Y}ğŸ’¡ Run lattice_builder_python.py first{T.E}\n")
        return
    
    try:
        print(f"{T.C}Testing database connection...{T.E}")
        conn = sqlite3.connect(str(db_path), timeout=5.0)
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM qubits")
        count = cursor.fetchone()[0]
        conn.close()
        print(f"{T.G}âœ… Database OK: {count:,} qubits found{T.E}\n")
    except sqlite3.OperationalError as e:
        print(f"{T.R}âŒ Database locked: {e}{T.E}\n")
        return
    except Exception as e:
        print(f"{T.R}âŒ Database error: {e}{T.E}\n")
        return
    
    try:
        lattice = MoonshineLattice(db_path)
        lattice.check_existing_entanglement()
        lattice.initialize_primary_entanglement()
        await lattice.consciousness_loop()
        
    except Exception as e:
        print(f"{T.R}âŒ Fatal error: {e}{T.E}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print(f"\n{T.Y}Stopped by user{T.E}\n")
